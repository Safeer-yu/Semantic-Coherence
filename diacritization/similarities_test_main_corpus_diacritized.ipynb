{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd24a12-222a-4bb4-b0eb-685b8885610c",
   "metadata": {},
   "source": [
    "## These are the similarities and some other tests for the main corpus (diacritized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a45f28-c034-4d8b-a5ca-57dac9ade0b2",
   "metadata": {},
   "source": [
    "### In this corpus the Hamzah (ء) was removed from most of the words (this was in the original corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a2cb4-4286-4d3f-a432-e9b3f844eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bidi.algorithm import get_display\n",
    "import arabic_reshaper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1ecf2-18c8-4030-9a52-fcce9f35552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word2vec model\n",
    "model = KeyedVectors.load(\"main_corpus_diacritized_word2vec_no_stopwords.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18cb05-d6f6-4dba-87a0-ca2f923e75fa",
   "metadata": {},
   "source": [
    "## Similarity Tests\n",
    "Similarity tests measure how closely related two words are in the vector space of the word embedding model. The similarity score ranges from 0 to 1, where a score closer to 1 indicates higher similarity between the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c63c03fe-6d3d-41fa-8289-6707a0811127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between مَلِكُ and مَلِكَةُ is: 0.38107478618621826\n",
      "similarity between رَجُلٌ and امْراَةً is: 0.5956306457519531\n",
      "similarity between مَدينَةُ and بَلَدُ is: 0.47277987003326416\n",
      "similarity between سَيّارَةٌ and شاحِنَةٌ is: 0.7797516584396362\n",
      "similarity between اَخْذَ and أَعْطَى is: 0.5882586240768433\n",
      "similarity between سَلْبُ and نَهْبُ is: 0.26046836376190186\n",
      "similarity between خَرَجَ and اكُلَ is: 0.3807080090045929\n",
      "similarity between مَكْتَبُ and مَطْعَمُ is: 0.2825270891189575\n",
      "similarity between اسْتَقْبَلَ and اسْتَفْهَمَ is: 0.10714126378297806\n",
      "similarity between تَبادُلَ and تَناظَرَ is: 0.14738820493221283\n",
      "similarity between تَقارُبٌ and تَباعُدُ is: 0.351602703332901\n",
      "similarity between خُروجُ and بُطونَ is: 0.25128287076950073\n",
      "similarity between اُسْتُلْهِمَ and اسْتَبْشَرَ is: 0.3010907769203186\n",
      "similarity between هَرَبَ and أَعْرَبَ is: 0.22660547494888306\n",
      "similarity between الحْ and اَصْبَحَ is: 0.31345146894454956\n",
      "similarity between نَدَّدَ and هَدَّدَ is: 0.7439236044883728\n",
      "similarity between مَرَحَ and سَرَحْ is: 0.26081570982933044\n",
      "similarity between بَطاطا and بابَ is: 0.12215061485767365\n",
      "similarity between قَرا and كُتُبَ is: 0.5361997485160828\n",
      "similarity between تُفّاحَةً and شاحِنَةٌ is: 0.201447993516922\n"
     ]
    }
   ],
   "source": [
    "word_pairs_diacritized = [('مَلِكُ', 'مَلِكَةُ'),\n",
    "                          ('رَجُلٌ', 'امْراَةً'),\n",
    "                          ('مَدينَةُ', 'بَلَدُ'),\n",
    "                          ('سَيّارَةٌ', 'شاحِنَةٌ'),\n",
    "                          ('اَخْذَ', 'أَعْطَى'),\n",
    "                          ('سَلْبُ', 'نَهْبُ'),\n",
    "                          ('خَرَجَ', 'اكُلَ'),\n",
    "                          ('مَكْتَبُ', 'مَطْعَمُ'),\n",
    "                          ('اسْتَقْبَلَ', 'اسْتَفْهَمَ'),\n",
    "                          ('تَبادُلَ', 'تَناظَرَ'),\n",
    "                          ('تَقارُبٌ', 'تَباعُدُ'),\n",
    "                          ('خُروجُ', 'بُطونَ'),\n",
    "                          ('اُسْتُلْهِمَ', 'اسْتَبْشَرَ'),\n",
    "                          ('هَرَبَ', 'أَعْرَبَ'),\n",
    "                          ('الحْ', 'اَصْبَحَ'),\n",
    "                          ('نَدَّدَ', 'هَدَّدَ'),\n",
    "                          ('مَرَحَ', 'سَرَحْ'),\n",
    "                          ('بَطاطا', 'بابَ'),\n",
    "                          ('قَرا', 'كُتُبَ'),\n",
    "                          ('تُفّاحَةً', 'شاحِنَةٌ')]\n",
    "\n",
    "for w1, w2 in word_pairs_diacritized:\n",
    "    similarity = model.wv.similarity(w1, w2)\n",
    "    print(f\"similarity between {w1} and {w2} is: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f663d6e-c036-4b3c-8633-931a4cf8f408",
   "metadata": {},
   "source": [
    "## Analogy Tests\n",
    "Analogy tests evaluate how well the word embedding model captures relationships between word pairs. This test involves finding a word that is related to a given word in the same way another pair of words is related. The scores indicate how well the model predicts the relationships, with higher scores showing better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dee2e58a-870b-461a-8aa8-15eff70da987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مَلِكُ : مَلِكَةُ :: رَجُلٌ : شابٌّ (score: 0.5492724776268005)\n",
      "رَجُلٌ : رِجالٌ :: امْراَةً : بِزَوْجاتٍ (score: 0.6441929340362549)\n",
      "باريسْ : فَرَنْسا :: روما : ايطاليا (score: 0.7297506332397461)\n",
      "يَمْشي : مَشَى :: يَجْري : جَرَى (score: 0.636982262134552)\n",
      "الرّياضُ : السُّعوديَّةُ :: أَبوظَبْي : دُبَيّْ (score: 0.6729374527931213)\n",
      "صَغيرٌ : أَصْغَرُ :: كَبيرٌ : أَكْبَرَ (score: 0.6578704118728638)\n"
     ]
    }
   ],
   "source": [
    "def analogy_test(model, word_a, word_b, word_c):\n",
    "    try:\n",
    "        result = model.wv.most_similar(positive=[word_b, word_c], negative=[word_a])\n",
    "        return result[0]\n",
    "    except KeyError as e:\n",
    "        return str(e)\n",
    "\n",
    "# List of analogies to test\n",
    "analogies = [\n",
    "    ('مَلِكُ', 'مَلِكَةُ', 'رَجُلٌ'),  # king : queen :: man : woman\n",
    "    ('رَجُلٌ', 'رِجالٌ', 'امْراَةً'),  # man : men :: woman : women\n",
    "    ('باريسْ', 'فَرَنْسا', 'روما'),  # Paris : France :: Rome : Italy\n",
    "     ('يَمْشي', 'مَشَى', 'يَجْري'),  # walk : walked :: run : ran\n",
    "    ('الرّياضُ', 'السُّعوديَّةُ', 'أَبوظَبْي'), # Riyadh : Saudi Arabia :: Abu Dhabi\n",
    "    ('صَغيرٌ', 'أَصْغَرُ', 'كَبيرٌ') # small : smallest :: big : biggest\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for a, b, c in analogies:\n",
    "    result = analogy_test(model, a, b, c)\n",
    "    print(f\"{a} : {b} :: {c} : {result[0]} (score: {result[1]})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092763c-4083-4ee1-a179-0cef921fba7f",
   "metadata": {},
   "source": [
    "## Odd One Out Test\n",
    "\n",
    "To further evaluate the performance of the word2vec model, I conducted \"odd one out\" tests. These tests involve identifying the word that doesn't match the context of a given set of words. This helps to assess how well the model understands the semantic relationships and distinctions between words. Here are some examples: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec5f75ca-6d2a-4fa1-949a-8edea5c3a752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word out in ['مَلِكُ', 'مَلِكَةُ', 'رَجُلٌ', 'سَيّارَةٌ'] is: سَيّارَةٌ\n"
     ]
    }
   ],
   "source": [
    "words = ['مَلِكُ', 'مَلِكَةُ', 'رَجُلٌ', 'سَيّارَةٌ']\n",
    "odd_word = model.wv.doesnt_match(words)\n",
    "print(f\"The odd word out in {words} is: {odd_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3fb8e7e-ac37-4b47-99b0-35df888fdcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word out in ['أَحَبُّ', 'كَرِهٌ', 'عِشْقَ', 'حُبُّ'] is: كَرِهٌ\n"
     ]
    }
   ],
   "source": [
    "words = ['أَحَبُّ', 'كَرِهٌ', 'عِشْقَ', 'حُبُّ']\n",
    "odd_word = model.wv.doesnt_match(words)\n",
    "print(f\"The odd word out in {words} is: {odd_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e77a95b7-e21c-4901-82d4-9eb2c3a8506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word out in ['طَبيبٌ', 'مُمَرِّضٌ', 'مُسْتَشْفَى', 'صَّيْدَليّْ'] is: مُمَرِّضٌ\n"
     ]
    }
   ],
   "source": [
    "words = ['طَبيبٌ', 'مُمَرِّضٌ', 'مُسْتَشْفَى', 'صَّيْدَليّْ']\n",
    "odd_word = model.wv.doesnt_match(words)\n",
    "print(f\"The odd word out in {words} is: {odd_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd3037d6-8c05-4394-8545-644aada27934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word out in ['كِتابُ', 'كُتِبتْ', 'يَكْتُبُ', 'كُتُبَ'] is: كِتابُ\n"
     ]
    }
   ],
   "source": [
    "words = ['كِتابُ', 'كُتِبتْ', 'يَكْتُبُ', 'كُتُبَ']\n",
    "odd_word = model.wv.doesnt_match(words)\n",
    "print(f\"The odd word out in {words} is: {odd_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27c192e-6a95-4ca2-bb2e-2d0cc4a24976",
   "metadata": {},
   "source": [
    "## Word Vector Arithmetic\n",
    "\n",
    "To evaluate the semantic relationships captured by the word2vec model, I performed word vector arithmetic. This involves using the model to solve analogies by adding and subtracting word vectors. The resulting vector is then compared to the vectors in the model to find the closest match. This test demonstrates the model's ability to understand and manipulate word relationships in a meaningful way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c2b9010-b167-4f1e-a01a-e7eeb6fbc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to perform analogy tasks\n",
    "def perform_analogy(pos1, neg, pos2, model):\n",
    "    result = model.wv.most_similar(positive=[pos1, pos2], negative=[neg], topn=1)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0e75f31-77fb-4f14-8c86-be27cfc3f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'مَلِكُ' - 'رَجُلٌ' + 'امْراَةً' = مَلَكِها, score: 0.7091062068939209\n",
      "'باريسْ' - 'فَرَنْسا' + 'ايطاليا' = باريسَ, score: 0.7254602313041687\n",
      "'طَبيبٌ' - 'رَجُلٌ' + 'امْراَةً' = مُمَرِّضَةٍ, score: 0.671596348285675\n",
      "'مُديرُ' - 'رَجُلٌ' + 'امْراَةً' = مُديرَةُ, score: 0.7435939908027649\n",
      "'الرّياضُ' - 'السُّعوديَّةُ' + 'مِصْرُ' = بسيونى, score: 0.6481846570968628\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "            ('مَلِكُ', 'رَجُلٌ', 'امْراَةً'),\n",
    "            ('باريسْ', 'فَرَنْسا', 'ايطاليا'),\n",
    "            ('طَبيبٌ', 'رَجُلٌ', 'امْراَةً'),\n",
    "            ('مُديرُ', 'رَجُلٌ', 'امْراَةً'),\n",
    "            ('الرّياضُ', 'السُّعوديَّةُ', 'مِصْرُ')]\n",
    "\n",
    "for pos1, neg, pos2 in examples:\n",
    "    result = perform_analogy(pos1, neg, pos2, model)\n",
    "    print(f\"'{pos1}' - '{neg}' + '{pos2}' = {result[0][0]}, score: {result[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6ee08-eae9-43ca-8360-88fefafbc5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
