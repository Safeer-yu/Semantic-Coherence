{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "365ccdb3",
   "metadata": {},
   "source": [
    "After building a dictionary of roots and their associated words, we compute the pairwise distances between all words within each root family using a word embedding model.\n",
    "For each root, we calculate the average distance across all word pairs.\n",
    "To reduce noise, roots with fewer than 10 associated words are excluded from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_semantic_coherence(root_to_words, model, threshold=10):\n",
    "    \"\"\"\n",
    "    Calculate semantic coherence for each root in the dictionary.\n",
    "    \"\"\"\n",
    "    semantic_coherence = {}\n",
    "\n",
    "    for root, words in root_to_words.items():\n",
    "        if len(words) < threshold:\n",
    "            continue  # Skip roots with fewer words than the threshold\n",
    "\n",
    "        distances = []\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i + 1, len(words)):\n",
    "                try:\n",
    "                    distance = model.wv.distance(words[i], words[j])\n",
    "                    distances.append(distance)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "        if distances:\n",
    "            average_distance = np.mean(distances)\n",
    "            semantic_coherence[root] = average_distance\n",
    "\n",
    "    return semantic_coherence\n",
    "\n",
    "def main():\n",
    "    # Load the dictionary and the word2vec model\n",
    "    dictionary_path = \"New-Corpus/output/updated_new_corpus_root_to_words_dict.pkl\"\n",
    "    model_path = \"New-Corpus/models/new_corp_word2vec.model\"\n",
    "    output_path = \"New-Corpus/output/new_corp_semantic_coherence_results.txt\"\n",
    "\n",
    "    print(\"Loading dictionary and word2vec model...\")\n",
    "    with open(dictionary_path, \"rb\") as file:\n",
    "        root_to_words = pickle.load(file)\n",
    "\n",
    "    model = Word2Vec.load(model_path)\n",
    "\n",
    "    # Calculate semantic coherence\n",
    "    print(\"Calculating semantic coherence...\")\n",
    "    semantic_coherence = calculate_semantic_coherence(root_to_words, model, threshold=5)\n",
    "\n",
    "    # Save the results to a file\n",
    "    print(\"Saving semantic coherence results to file...\")\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for root, coherence in semantic_coherence.items():\n",
    "            file.write(f\"Root: {root}, Semantic Coherence: {coherence}\\n\")\n",
    "\n",
    "    print(f\"Semantic coherence results saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4af07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_semantic_coherence(file_path):\n",
    "    roots = []\n",
    "    coherences = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            root, coherence = line.strip().split(\", \")\n",
    "            roots.append(root.split(\": \")[1])\n",
    "            coherences.append(float(coherence.split(\": \")[1]))\n",
    "    return roots, coherences\n",
    "roots, coherences = load_semantic_coherence(\"New-Corpus/output/new_corp_semantic_coherence_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a07eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(coherences):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(coherences, kde=True, bins=30)\n",
    "    plt.title('Distribution of Semantic Coherence Values')\n",
    "    plt.xlabel('Semantic Coherence')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks([i/10 for i in range(11)])\n",
    "    plt.show()\n",
    "plot_histogram(coherences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b803153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_scatter_with_average(roots, coherences):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Reduce point size and add transparency\n",
    "    plt.scatter(range(len(coherences)), coherences, alpha=0.5, s=3)\n",
    "    \n",
    "    # Calculate and plot the average coherence\n",
    "    avg_coherence = np.mean(coherences)\n",
    "    plt.axhline(y=avg_coherence, color='red', linestyle='--', label=f'Average Coherence: {avg_coherence:.2f}')\n",
    "    \n",
    "    plt.title('Scatter Plot of Semantic Coherence Values by Root')\n",
    "    plt.xlabel('Root Index')\n",
    "    plt.ylabel('Semantic Coherence')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_scatter_with_average(roots, coherences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_hpc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
